import os

import numpy as np
import torch
from skimage import io, util, color
from torch.utils.data import Dataset


class VesselDataset(Dataset):
    """
    PyTorch Dataset for loading vessel segmentation image-mask pairs.

    Loads preprocessed patches from disk, handles grayscale conversion,
    normalization, and mask inversion for training data.

    Attributes:
        image_dir: Directory containing image patches.
        mask_dir: Directory containing corresponding mask patches.
        transform: Optional transforms to apply.
        validation: If False, inverts masks (training data has inverted masks).
    """

    def __init__(self, image_dir, mask_dir, transform=None, validation=False):
        self.image_dir = image_dir
        self.mask_dir = mask_dir
        self.transform = transform
        self.validation = validation
        # Get a sorted list of image filenames
        self.image_filenames = sorted([f for f in os.listdir(image_dir) if f.endswith('.tif')])

    def __len__(self):
        return len(self.image_filenames)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()

        # Construct file paths
        image_filename = self.image_filenames[idx]
        image_path = os.path.join(self.image_dir, image_filename)
        mask_path = os.path.join(self.mask_dir, image_filename)  # Mask has the same filename
        # Load image and mask
        image = io.imread(image_path)
        mask = io.imread(mask_path)

        # If the image is loaded with a channel dimension, convert to grayscale
        if image.ndim == 3:
            image = color.rgb2gray(image)

        mask = mask > 0
        if not self.validation:
            mask = np.logical_not(mask)

        image = util.img_as_float(image)
        mask = mask.astype(float)

        image = torch.from_numpy(image).float()
        mask = torch.from_numpy(mask).long()

        # 4. Add a channel dimension (C, H, W) as expected by PyTorch models
        image = image.unsqueeze(0)  # From (H, W) to (1, H, W)

        sample = {'image': image, 'mask': mask}

        if self.transform:
            sample = self.transform(sample)

        return sample


if __name__ == '__main__':
    # --- A quick test to see if the dataset works correctly ---
    root = os.path.abspath(os.path.join(os.path.dirname(__file__), '../..'))
    train_image_dir = os.path.join(root, 'Data/preprocessed/train/image')
    train_mask_dir = os.path.join(root, 'Data/preprocessed/train/mask')

    print(f"Looking for training images in: {os.path.abspath(train_image_dir)}")
    print(f"Looking for training masks in: {os.path.abspath(train_mask_dir)}")

    # Check if the directories exist
    if not os.path.isdir(train_image_dir) or not os.path.isdir(train_mask_dir):
        print("\nError: Preprocessed data directories not found!")
        print("Please ensure you have run the data_preprocessing.py script")
        print("and that the data is located in Solution/Data/preprocessed/")
    else:
        # Create an instance of the dataset
        vessel_dataset = VesselDataset(image_dir=train_image_dir, mask_dir=train_mask_dir)

        print(f"\nDataset created successfully!")
        print(f"Number of training samples: {len(vessel_dataset)}")

        # Get a sample from the dataset
        if len(vessel_dataset) > 0:
            sample = vessel_dataset[0]
            image, mask = sample['image'], sample['mask']

            print(f"Sample image shape: {image.shape}")  # Should be [1, 512, 512]
            print(f"Sample image dtype: {image.dtype}")  # Should be torch.float32
            print(f"Sample mask shape: {mask.shape}")  # Should be [512, 512]
            print(f"Sample mask dtype: {mask.dtype}")  # Should be torch.int64
            print(f"Unique values in sample mask: {torch.unique(mask)}")  # Should be [0, 1]
        else:
            print("Dataset is empty. No patches were found.")
